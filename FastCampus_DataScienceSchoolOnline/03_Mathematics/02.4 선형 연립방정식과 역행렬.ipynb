{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02.4 선형 연립방정식과 역행렬\n",
    "- https://datascienceschool.net/view-notebook/927d7f7972dd434ead9d294169ae7f34/\n",
    "- 선형 예측 모형은 입력 데이터 벡터와 가중치 벡터의 내적으로 계산된 예측값이 실제 출력 데이터와 유사한 값을 출력하도록 하는 모영을 말한다.\n",
    "- 과거 입력 데이터들과 그 입력 데이터들의 실제 출력 데이터와의 관계를 통해 가중치 벡터를 구해야 하며 여기서 선형연립방정식과 역행렬의 개념이 필요하다.\n",
    "- 이러한 과정을 거쳐서 가중치 벡터를 구해내는 과정을 선형 예측 모형을 알아내는 과정, 즉 모델링 과정이라고 말할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형 연립방정식; system of linear equations\n",
    "- 복합의 미지수를 포함하는 복합의 선형방정식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\begin{matrix}\n",
    "a_{11} x_1 & + \\;& a_{12} x_2   &\\; + \\cdots + \\;& a_{1M} x_M &\\; = \\;& b_1 \\\\\n",
    "a_{21} x_1 & + \\;& a_{22} x_2   &\\; + \\cdots + \\;& a_{2M} x_M &\\; = \\;& b_2 \\\\\n",
    "\\vdots\\;\\;\\; &   & \\vdots\\;\\;\\; &                & \\vdots\\;\\;\\; &     & \\;\\vdots \\\\\n",
    "a_{N1} x_1 & + \\;& a_{N2} x_2   &\\; + \\cdots + \\;& a_{NM} x_M &\\; = \\;& b_N \\\\\n",
    "\\end{matrix}\n",
    "\\tag{2.4.2}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} & \\cdots & a_{1M} \\\\\n",
    "a_{21} & a_{22} & \\cdots & a_{2M} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{N1} & a_{N2} & \\cdots & a_{NM} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_M\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_N\n",
    "\\end{bmatrix}\n",
    "\\tag{2.4.3}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} & \\cdots & a_{1M} \\\\\n",
    "a_{21} & a_{22} & \\cdots & a_{2M} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{N1} & a_{N2} & \\cdots & a_{NM} \\\\\n",
    "\\end{bmatrix}\n",
    ", \\;\\;\n",
    "x = \n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_M\n",
    "\\end{bmatrix}\n",
    ", \\;\\;\n",
    "b=\n",
    "\\begin{bmatrix}\n",
    "b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_N\n",
    "\\end{bmatrix}\n",
    "\\tag{2.4.4}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "Ax = b  \n",
    "\\tag{2.4.5}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A: 계수행렬 (coefficient matrix) --> 입력 데이터 매트릭스\n",
    "- x: 미지수벡터 (unknown vector) --> 가중치 벡터\n",
    "- b: 상수벡터 (constatnt vector) --> 출력 데이터 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $Ax = b$ 에서 $x$를 구하는 법\n",
    "- $A, x, b$ 가 스칼라 실수라면, $x = \\dfrac{b}{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $A, x, b$ 가 벡터/행렬이라면, $x = A^{-1}b$\n",
    "    - 여기서 역행렬의 개념이 필요하게 됨\n",
    "    - $x$, 즉 가중치 벡터를 구해내면 모델링을 완료한 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 역행렬; inverse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 행렬 A의 역행렬은 본래의 행렬 A와 곱했을 때 그 결과를 항등행렬로 만드는 행렬을 말한다.\n",
    "    - 행렬과 행렬의 곱이 항등행렬(Identity Matrix)이 되려면 그 두개의 행렬은 \"정방행렬(square matrix)\"이어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "A^{-1} A = A A^{-1} = I  \n",
    "\\tag{2.4.9}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 역행렬은 존재할 수도, 존재하지 않을 수 있다.\n",
    "    - 역행렬이 존재하는 행렬: 가역행렬(invertible matrix), 정칙행렬(regular matrix), 비특이행렬(signular matrix)\n",
    "    - 역행렬이 존재하지 않는 행렬: 비가역행렬(non-invertible matrix), 특이행렬(singular matrix), 퇴화행렬(degenerate matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역행렬의 성질"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $(A^{T})^{-1} = (A^{-1})^{T}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. $(AB)^{-1} = B^{-1} A^{-1} $\n",
    "    - $(ABC)^{-1} = C^{-1} B^{-1} A^{-1} $\n",
    "    - cf. $(AB)^T = B^T A^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역행렬의 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "A^{-1} = \\dfrac{1}{\\det (A)} C^T = \\dfrac{1}{\\det (A)} \n",
    "\\begin{bmatrix}\n",
    "C_{1,1} & \\cdots & C_{N,1}  \\\\\n",
    "\\vdots  & \\ddots & \\vdots   \\\\\n",
    "C_{1,N} & \\cdots & C_{N,N}  \\\\\n",
    "\\end{bmatrix}\n",
    "\\tag{2.4.14}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $C_{i,j}$: 행렬 $A$의 $i,j$번째 원소에 대해 정의한 Cofactor를 의미함\n",
    "- $C$: cofactor들로 이루어진 행렬을 의미함\n",
    "    - 여인수행렬(matrix of cofactors, cofactor matrix)\n",
    "- $C^T$: 여인수행렬의 전치행렬을 의미함 \n",
    "    - 수반행렬, 어드조인트행렬(adjoint matrix, adjugate matrix)\n",
    "    - $adj(A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 식에서 $det(A)$가 0이면 $A^{-1}$은 존재하지 않느다. (분모가 0인 수는 존재하지 않으므로)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역행렬에 대한 몇가지 정리\n",
    "- '이런게 있었었지' 라고 생각해낼 수 있으면 될 뿐, 외울 필요는 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 셔먼-모리슨(Sherman–Morrison) 공식\n",
    "    \\begin{align}\n",
    "    (A+uv^T)^{-1} = A^{-1} - {A^{-1}uv^T A^{-1} \\over 1 + v^T A^{-1}u} \n",
    "    \\tag{2.4.21}\n",
    "    \\end{align}\n",
    "    - $A$가 조금 변하면 $A^{-1}$도 조금씩 변하는데, 그 변하는 비중에 대해 알 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 우드베로(woodbury) 공식\n",
    "    \\begin{align}\n",
    "    \\left(A+UCV \\right)^{-1} = A^{-1} - A^{-1}U \\left(C^{-1}+VA^{-1}U \\right)^{-1} VA^{-1} \n",
    "    \\tag{2.4.22}\n",
    "    \\end{align}\n",
    "    - 셔먼-모리슨 공식의 약간 develop 버전"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 분할행렬(partitional matrix)의 역행렬\n",
    "    \\begin{align}\n",
    "    \\begin{bmatrix}\n",
    "    A_{11} & A_{12} \\\\\n",
    "    A_{21} & A_{22} \n",
    "    \\end{bmatrix}^{-1}\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "    A_{11}^{-1}(I + A_{12}FA_{11}^{-1}) & -A_{11}^{-1}A_{12}F \\\\\n",
    "    -FA_{21}A_{11}^{-1} & F\n",
    "    \\end{bmatrix}\n",
    "    \\tag{2.4.23}\n",
    "    \\end{align}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "F = (A_{22} - A_{21}A_{11}^{-1}A_{12})^{-1}\n",
    "\\tag{2.4.24}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "$$or$$\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "F = (A_{11} - A_{12}A_{22}^{-1}A_{21})^{-1}\n",
    "\\tag{2.4.25}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy를 통한 역행렬 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,1,0],[0,1,1],[1,1,1]]) #임의의 행렬 A 정의\n",
    "A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1.,  1.],\n",
       "       [ 1.,  1., -1.],\n",
       "       [-1.,  0.,  1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ainv = np.linalg.inv(A) # numpy의 linalg 서브 패키지를 이용해서 invert matrix 구하기\n",
    "Ainv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ainv@A # 어느 행렬과 그 역행렬의 곱은 항상 identity matrix 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A@Ainv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형 연립방정식과 선형 예측모형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형 예측모형의 가중치벡터를 구하는 문제는 선형 연립방정식 문제를 푸는 것과 같다.\n",
    "    - 선형 연립방정식: $ Ax = b$\n",
    "    - 선형예측모형: $ Xw = \\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\begin{matrix}\n",
    "x_{11} w_1 & + \\;& x_{12} w_2   &\\; + \\cdots + \\;& x_{1N} w_N &\\; = \\;& y_1 \\\\\n",
    "x_{21} w_1 & + \\;& x_{22} w_2   &\\; + \\cdots + \\;& x_{2N} w_N &\\; = \\;& y_2 \\\\\n",
    "\\vdots\\;\\;\\; &   & \\vdots\\;\\;\\; &                & \\vdots\\;\\;\\; &     & \\;\\vdots \\\\\n",
    "x_{N1} w_1 & + \\;& x_{N2} w_2   &\\; + \\cdots + \\;& x_{NN} w_N &\\; = \\;& y_N \\\\\n",
    "\\end{matrix}\n",
    "\\tag{2.4.30}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy를 이용해서 선형 연립방정식 풀기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Xw = \\hat{y}$$\n",
    "\n",
    "\n",
    "$$w = X^{-1}\\hat{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형연립방정식을 풀기 위해서 inv()를 구한 후 벡터 y에 직접 곱해도 되겠지만, 보통은 lstsq() 명령을 사용한다.\n",
    "- inv() 명령보다 lstsq() 명령이 수치오자도 적고, 코드도 간단하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lstsq() 명령은 행렬 A와 b를 인수로 받고, \"최소차승문제(least sqaure problem)\"을 푸는 함수다,\n",
    "    - x: 답\n",
    "    - resid: 잔차제곱합(residual sum of sqaures)\n",
    "    - rank: 랭크 - 행렬 $X$가 얼마나 독립적인 데이터, 변수였는지에 대한 여부 > 높을 수록 입력 데이터가 독립적이며 모델의 정확도도 높을 가능성\n",
    "    - s: 특이값 (sigular value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6, -3,  0],\n",
       "       [ 3,  6,  9],\n",
       "       [12, 15, 18]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = ((np.arange(9)-2)*3).reshape(3,3) #임의의 행렬 X\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[2],[4],[1]]) # 임의의 행렬 y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.46296296]\n",
      " [-0.01851852]\n",
      " [ 0.42592593]] \n",
      "\n",
      "잔차제곱합: [] \n",
      "\n",
      "랭크: 2 \n",
      "\n",
      "특이값: [2.88526380e+01 5.61473790e+00 1.00534292e-16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x, resid, rank, s = np.linalg.lstsq(X,y) #X, y에 대한 최소차증문제 풀기\n",
    "print(x, '\\n\\n잔차제곱합:',resid, '\\n\\n랭크:',rank, '\\n\\n특이값:',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 연습문제 2.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston # 보스턴 집값 문제: 보스턴 내 각 지역(town)의 주택가격에 대한 예측 문제\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "A = X[:4, [0, 4, 5, 6]]  # 'CRIM(범죄율)', 'NOX(공기오염도)', 'RM(방의개수)', 'AGE(오래된 정도)'\n",
    "b = y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # dataset 크기 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.320e-03, 5.380e-01, 6.575e+00, 6.520e+01],\n",
       "       [2.731e-02, 4.690e-01, 6.421e+00, 7.890e+01],\n",
       "       [2.729e-02, 4.690e-01, 7.185e+00, 6.110e+01],\n",
       "       [3.237e-02, 4.580e-01, 6.998e+00, 4.580e+01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A # 임의의 행렬 A 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b # 행렬 A에 대한 출력 데이터 벡터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-3.12710043e+02, -1.15193942e+02,  1.44996465e+01, -1.13259317e-01]),\n",
       " array([], dtype=float64),\n",
       " 4,\n",
       " array([1.28391009e+02, 2.97333579e+00, 7.58898410e-02, 7.51932881e-03]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.lstsq(A,b) # 임의 추출한 A, b에 대한 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-9.28965170e-02,  4.87149552e-02, -4.05997958e-03,  2.85399882e+00,\n",
       "        -2.86843637e+00,  5.92814778e+00, -7.26933458e-03, -9.68514157e-01,\n",
       "         1.71151128e-01, -9.39621540e-03, -3.92190926e-01,  1.49056102e-02,\n",
       "        -4.16304471e-01]),\n",
       " array([12228.04626104]),\n",
       " 13,\n",
       " array([1.25851816e+04, 3.44597406e+03, 6.45757109e+02, 4.02050461e+02,\n",
       "        1.58964612e+02, 1.21502936e+02, 9.04652420e+01, 7.79311708e+01,\n",
       "        6.50828345e+01, 2.46251803e+01, 1.80945451e+01, 5.51505065e+00,\n",
       "        1.48096916e+00]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.lstsq(X,y) # 전체 데이터셋인 X,y에 대한 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미지수의 수와 방정식의 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X \\in R^{N*M}$ 일 때,\n",
    "- 행의 개수($N$): 방정식의 개수, 데이터의 개수\n",
    "- 열의 개수($M$): 미지수의 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $N = M$\n",
    "    - 지금까지 예제로 보았던 경우\n",
    "    - $X$가 정방행렬이기 때문에 역행렬 계산 및 적용 등에 무리 없음\n",
    "    \n",
    "    \n",
    "2. $N < M$\n",
    "    - 해가 무수히 많이 존재하기 때문에 방정식을 풀 수 없음.\n",
    "    - 즉 모델링을 할 수 없음\n",
    "\n",
    "3. $N > M$\n",
    "    - 실제로 접하는 대부분의 예측 문제들은 상당히 많은 데이터(=방정식)를 다루기 때문에 대부분의 예측문제는 이 경우에 해당할 것\n",
    "    - 모든 데이터가 완벽히 선형에 있지 않는 이상, 모든 방정식을 만족하는 해가 존재하지 않게됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최소차승문제 (least squre problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$N > M$ 일 때 선립 연립방정식을 구하는 방식으로는 해를 구할 수 없다. (불능)\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{matrix}\n",
    "x_1 & + & x_2 &   &     & = & 2  \\\\\n",
    "    &   & x_2 & + & x_3 & = & 2  \\\\\n",
    "x_1 & + & x_2 & + & x_3 & = & 3  \\\\\n",
    "x_1 & + & x_2 & + & 2x_3 & = & 4.1  \\\\\n",
    "\\end{matrix}\n",
    "\\tag{2.4.37}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럴 때는 차선으로 \"좌변(예측값)과 우변(목푯값)을 완벽하게 일치\"시키는 것에서 \"좌변(예측값)과 우변(목푯값)을 거의 비슷하게 일치\"시키는 것으로 문제를 바꿔서 생각할 수 있다.\n",
    "- \"좌변(예측값)과 우변(목푯값)을 완벽하게 일치\"시키는 문제 $\\rightarrow$ **선형 연립방정식**\n",
    "- \"좌변(예측값)과 우변(목푯값)을 거의 비슷하게 일치\"시키는 문제 $=$ \"좌변과 우변의 차이를 최소화\"시키는 문제 $\\rightarrow$ **최소차승문제**\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{matrix}\n",
    "x_1 & + & x_2 &   &     & = & 2 & &\\\\\n",
    "    &   & x_2 & + & x_3 & = & 2 & &\\\\\n",
    "x_1 & + & x_2 & + & x_3 & = & 3 & &\\\\\n",
    "x_1 & + & x_2 & + & 2x_3 & = & 4 & \\approx & 4.1\n",
    "\\end{matrix}\n",
    "\\tag{2.4.38}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예측값과 목푯값의 차이 $\\rightarrow$ 잔차(residual)\n",
    "\n",
    "$$e = Ax - b  $$\n",
    "\n",
    "$$e = Xw - \\hat{y} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 잔차(residual)은 벡터이기 때문에, \"잔차의 크기를 최소화\"한다는 것은 곧 \"벡터의 놈(Norm)을 최소화\"한다는 것을 의미한다.\n",
    "    - *trace, determinant는 정방행렬(square matrix)에만 적용 가능하다.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 놈(Norm)의 성질에 의해 \"norm을 최소화\"하는 문제는 \"norm의 제곱을 최소화\"하는 것과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 내용에 따라 최소차승문제(least square problem)의 정의는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "x = \\text{arg} \\min_x e^Te = \\text{arg} \\min_x  \\; (Ax-b)^T(Ax-b)  \n",
    "\\tag{2.4.41}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "Ax \\approx b \n",
    "\\tag{2.4.42}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "A^TAx \\approx A^Tb \n",
    "\\tag{2.4.43}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 비록 $A$가 정방행렬이 아니라도, $A^TA$는 정방행렬이다.\n",
    "\n",
    "- 정방행렬 $A^TA$의 역행렬 $(A^TA)^{-1}$이 존재한다고 가정하면,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "(A^TA)^{-1}(A^TA)x \\approx (A^TA)^{-1}A^Tb \n",
    "\\tag{2.4.44}\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "x \\approx ((A^TA)^{-1}A^T) b  \n",
    "\\tag{2.4.45}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 엄밀한 증명은 행렬의 미분과 최적화 개념 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 행렬 A의 의사역행렬(pseudo inverse)\n",
    "    - 위 식에서 나온 $((A^TA)^{-1}A^T)$를 pseudo inverse라고 정의함\n",
    "    - 줄여서 $A^+$로 표시할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "A^{+} = (A^TA)^{-1}A^T \n",
    "\\tag{2.4.46}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "x \\approx A^+ b  \n",
    "\\tag{2.4.47}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 정리하자면,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X in R^{N*M}$ 일 때,$Xw = \\hat{y}\\$의 풀이는 다음과 같다.\n",
    "\n",
    "1. $N = M$, $w = X^{-1}\\hat{y}$\n",
    "2. $N > M$, $w \\approx X^{+}\\hat{y}$\n",
    "3. $N < M$, $w$: 부정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
